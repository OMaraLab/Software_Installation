# Billy's GROMACS-Plumed Installation (Build from Source)

## Overview
This installation builds GROMACS-2023.5 patched with Plumed-2.9.0 from source on Bunya with H100 GPUs. This version provides approximately 5% better performance compared to the module-based installation but requires more compilation steps.

## Prerequisites
- Access to Bunya HPC cluster
- Valid account with GPU allocation
- Sufficient disk space in scratch directory (~10GB)

## Installation Steps

### Step 1: Start an Interactive Session
Request compute resources with H100 GPU access:
```bash
salloc --nodes=1 --ntasks-per-node=1 --cpus-per-task=16 --mem=500G --job-name=GROMACS_INSTALL --time=10:00:00 --partition=gpu_cuda --qos=gpu --account=a_omara --gres=gpu:h100:1 
srun --export=PATH,TERM,HOME,LANG --pty /bin/bash -l
```

### Step 2: Load Dependencies
Load required modules and set environment variables:
```bash
module load cmake/3.26.3-gcccore-12.3.0
module load openmpi/4.1.5-gcc-12.3.0
module load cuda/12.2.0
export MPIEXEC=srun
```

### Step 3: Download and Extract Source Code
Download and extract both GROMACS and Plumed source code:
```bash
wget https://ftp.gromacs.org/gromacs/gromacs-2023.5.tar.gz
wget https://github.com/plumed/plumed2/releases/download/v2.9.0/plumed-src-2.9.0.tgz
tar -xzf plumed-src-2.9.0.tgz
tar -xzf gromacs-2023.5.tar.gz
```

### Step 4: Configure and Compile Plumed
Build Plumed from source with all modules enabled:
```bash
cd /scratch/user/uqbwil32/plumed-2.9.0
./configure --prefix=/scratch/user/uqbwil32/plumed-2.9.0/ --enable-modules=all --enable-mpi
make -j 16
make install
source sourceme.sh
```

**Note**: Update the path `/scratch/user/uqbwil32/` to your actual scratch directory.

### Step 5: Patch Plumed to GROMACS
Apply Plumed patches to GROMACS source code:
```bash
cd /scratch/user/uqbwil32/gromacs-2023.5
mkdir build
mpirun -np 1 plumed patch -p
```
When prompted, select `gromacs-2023.5` from the list of available options.

### Step 6: Configure and Compile GROMACS
Configure GROMACS with optimised settings:
```bash
cd build
cmake .. -DGMX_BUILD_OWN_FFTW=ON -DREGRESSIONTEST_DOWNLOAD=ON -DCMAKE_INSTALL_PREFIX=/scratch/user/uqbwil32/gromacs-2023.5/ -DGMX_MPI=on -DGMX_GPU=CUDA
```

**Configuration Flags Explained**:
- `GMX_BUILD_OWN_FFTW=ON`: Build optimised FFTW library
- `REGRESSIONTEST_DOWNLOAD=ON`: Download and enable regression tests
- `CMAKE_INSTALL_PREFIX`: Installation directory (update to your path)
- `GMX_MPI=on`: Enable MPI support for parallel computing
- `GMX_GPU=CUDA`: Enable CUDA GPU acceleration

### Step 7: Build and Install GROMACS
Compile, test, and install GROMACS:
```bash
make -j 16 
make check
make install
```

**Build Process**:
- `make -j 16`: Compile using 16 parallel processes
- `make check`: Run regression tests to verify installation
- `make install`: Install binaries to specified prefix directory

### Step 8: Set Up Environment
Add GROMACS to your environment:
```bash
source /scratch/user/uqbwil32/gromacs-2023.5/bin/GMXRC
```

## Verification
Test the installation:
```bash
gmx_mpi --version
plumed --version
```

## Performance Notes
- CUDA GPU capabilities are automatically detected from SLURM job allocation
- This version provides ~5% performance improvement over module-based installations
- Optimised FFTW library contributes to enhanced performance
- All modules and regression tests are included for maximum functionality

## Troubleshooting
- Ensure sufficient disk space in scratch directory
- Verify all modules are loaded before compilation
- Check that GPU allocation is active in interactive session
- Update all file paths to match your actual directory structure
